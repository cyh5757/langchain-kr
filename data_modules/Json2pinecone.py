import os
import json
import uuid
import concurrent.futures
from typing import List, Any

import pandas as pd
from tqdm import tqdm
from dotenv import load_dotenv
from langchain.docstore.document import Document
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from langchain_teddynote import logging

# LangSmith ì¶”ì  ì„¤ì •
logging.langsmith("Json2pinecone")

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "snack-db")
PINECONE_REGION = os.getenv("PINECONE_REGION", "us-east-1")
NAMESPACE = "snack-rag-namespace"

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
if not PINECONE_API_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'PINECONE_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# 2. JSON ë°ì´í„°ë¥¼ LangChain Document ê°ì²´ë¡œ ë³€í™˜
def load_documents(filepath="Snack_data/snack_data.json") -> List[Document]:
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)

    documents = [
        Document(
            page_content=doc["page_content"],
            metadata=doc["metadata"]
        )
        for doc in data
    ]
    return documents

# 3. Pinecone ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„± (ìµœì´ˆ 1íšŒë§Œ ì‚­ì œ)
def get_index(delete_first=False):
    pc = Pinecone(api_key=PINECONE_API_KEY)


    if PINECONE_INDEX_NAME not in pc.list_indexes().names():
        print(f"ğŸ“Œ ì¸ë±ìŠ¤ '{PINECONE_INDEX_NAME}' ìƒì„± ì¤‘...")
        pc.create_index(
            name=PINECONE_INDEX_NAME,
            dimension=3072,  # text-embedding-3-large ëª¨ë¸ì˜ ì¶œë ¥ ì°¨ì›
            metric="dotproduct",
            spec=ServerlessSpec(cloud="aws", region=PINECONE_REGION)
        )
        print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {PINECONE_INDEX_NAME}")

    return pc.Index(PINECONE_INDEX_NAME)

# 4. ë¬¸ì„œ ë²¡í„° ì„ë² ë”© ë° Pinecone ì—…ë¡œë“œ
def process_batch(batch: List[Document], embeddings: OpenAIEmbeddings, index: Any):
    texts = [doc.page_content for doc in batch]
    metadatas = [doc.metadata for doc in batch]
    vectors = embeddings.embed_documents(texts)

    index.upsert(
        vectors=[
            (str(uuid.uuid4()), vector, metadata)
            for vector, metadata in zip(vectors, metadatas)
        ],
        namespace=NAMESPACE
    )

# 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§
if __name__ == "__main__":
    print("ğŸš€ ê³¼ì ì •ë³´ ë²¡í„° ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")

    try:
        print("ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
        documents = load_documents()

        print("ğŸ“Œ Pinecone ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
        index = get_index(delete_first=False)  # í•„ìš”ì‹œ Trueë¡œ ë³€ê²½

        print("ğŸ”— OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")  # 3072ì°¨ì› ì¶œë ¥

        BATCH_SIZE = 64
        batches = [documents[i:i + BATCH_SIZE] for i in range(0, len(documents), BATCH_SIZE)]

        print("ğŸš€ ë²¡í„° ì—…ë¡œë“œ ì¤‘...")
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = [
                executor.submit(process_batch, batch, embeddings, index)
                for batch in batches
            ]
            for _ in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):
                pass

        print("âœ… ì „ì²´ ë²¡í„° ì €ì¥ ì™„ë£Œ: Pinecone ì—…ë¡œë“œ ì„±ê³µ")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
