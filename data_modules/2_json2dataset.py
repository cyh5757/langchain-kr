import os
import time
import pandas as pd
from ragas.testset.generator import TestsetGenerator
from ragas.testset.evolutions import simple, reasoning, multi_context, conditional
from ragas.llms import LangchainLLMWrapper
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.testset.extractor import KeyphraseExtractor
from ragas.testset.docstore import InMemoryDocumentStore

from langchain_community.document_loaders import JSONLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

from langchain.schema import Document

# ------------------------------
# 1. ë¬¸ì„œ ë¡œë“œ ë° ì„¤ì •
# ------------------------------
loader = JSONLoader(
    file_path="Snack_data/snack_vector.json",
    jq_schema=".[]",            # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ê°ì²´ë“¤ í•˜ë‚˜ì”© ì²˜ë¦¬
    content_key="text",         # ì´ í‚¤ì˜ ê°’ì„ page_contentë¡œ ì‚¬ìš©
    text_content=True,          # ì´ ê°’ì´ ë¬¸ìì—´ì„ì„ ëª…ì‹œ
    metadata_func=lambda sample, _: sample.get("metadata", {})
)

docs = loader.load()
docs = docs[:20]
for doc in docs:
    doc.metadata["filename"] = doc.metadata.get("source", "snack_vector.json")

print(f"âœ… ì „ì²´ ë¬¸ì„œ ìˆ˜: {len(docs)}")

# ------------------------------
# 2. RAGAS ì„¤ì •
# ------------------------------
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
generator_llm = ChatOpenAI(model="gpt-4o")
critic_llm = ChatOpenAI(model="gpt-4o")
langchain_llm = LangchainLLMWrapper(generator_llm)
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
ragas_embeddings = LangchainEmbeddingsWrapper(embeddings)

keyphrase_extractor = KeyphraseExtractor(llm=langchain_llm)
docstore = InMemoryDocumentStore(
    splitter=splitter,
    embeddings=ragas_embeddings,
    extractor=keyphrase_extractor,
)
generator = TestsetGenerator.from_langchain(
    generator_llm, critic_llm, ragas_embeddings, docstore=docstore
)

# ------------------------------
# 3. ë°˜ë³µ ìƒì„± ì„¤ì •
# ------------------------------
distributions = {
    simple: 0.3,
    reasoning: 0.3,
    multi_context: 0.2,
    conditional: 0.2,
}

batch_size = 20
total_test_size = 5
results = []

print("ğŸš€ í…ŒìŠ¤íŠ¸ì…‹ ìƒì„± ì‹œì‘...")

for i in range(0, len(docs), batch_size):
    doc_batch = docs[i:i + batch_size]
    if not doc_batch:
        continue

    try:
        testset = generator.generate_with_langchain_docs(
            documents=doc_batch,
            test_size=min(batch_size, total_test_size - len(results)),
            distributions=distributions,
            with_debugging_logs=True,
            raise_exceptions=False,
        )
        test_df = testset.to_pandas()
        results.append(test_df)

        print(f"âœ… Batch {i // batch_size + 1}: {len(test_df)}ê°œ ìƒì„±ë¨")
        time.sleep(1.5)  # â±ï¸ OpenAI TPM ì œí•œ íšŒí”¼ìš© ë”œë ˆì´

        # ì¤‘ê°„ ì €ì¥
        combined_df = pd.concat(results, ignore_index=True)
        combined_df.to_csv("Snack_data/ragas_synthetic_dataset.csv", index=False)

        # ìµœëŒ€ ìˆ˜ëŸ‰ ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
        if len(combined_df) >= total_test_size:
            break

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ (Batch {i // batch_size + 1}): {e}")
        time.sleep(5)

print("ğŸ‰ ì „ì²´ ìƒì„± ì™„ë£Œ âœ…")
